{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "native-dinner",
   "metadata": {},
   "source": [
    "# Excercise 4: Containerize Model\n",
    "\n",
    "Now that we have a model, we can build a container around it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-trademark",
   "metadata": {},
   "source": [
    "## Excercise 1: Evaluate Dummy Service \n",
    "\n",
    "Currently our frontend calls a dummy service to check if a user is eligible. \n",
    "\n",
    "Our dummy service already provides the basic infrastrucure to serve a real sklearn model.\n",
    "\n",
    "Read through the `DummyModel.py`, `requirements.txt` and the `Dockerfile` at `services/dummy` and try to understand whats going on.\n",
    "\n",
    "Questions\n",
    "- What is the predicion of our dummy service?\n",
    "- How could you adapt our dummy service to serve our model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-pakistan",
   "metadata": {},
   "source": [
    "## Excercise 2: Create wrapper around our model\n",
    "\n",
    "Now that we understand our dummy service, we want to load our previously trained model. \n",
    "\n",
    "1. Copy dummy service\n",
    "  \n",
    "  `services/dummy/DummyModel.py`,`services/dummy/requirements.txt` and `services/dummy/Dockerfile` to \n",
    "  `services/eligibilty/EligibilityModel.py`, `services/eligibilty/requirements.txt` and `services/eligibilty/Dockerfile`.\n",
    "2. Copy our model from `notebooks/model/elibility_model.joblib` to `services/eligibilty/elibility_model.joblib`\n",
    "3. Adjust `EligibilityModel.py` to load our pipeline from the joblib file and call our pipeline. Use the function `load` from joblib to load our model. See https://scikit-learn.org/stable/modules/model_persistence.html#python-specific-serialization\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-classics",
   "metadata": {},
   "source": [
    "## Excercise 3: Build docker image and start it\n",
    "\n",
    "To serve our model from Docker we need to adjust the Dockerfile at `services/eligibilty/Dockerfile`:\n",
    "\n",
    "Change `ENV MODEL_NAME DummyModel` to `ENV MODEL_NAME EligibilityModel`\n",
    "\n",
    "And adjust the `docker-compose.yml` to use our new elibility service instead of dummy:\n",
    "\n",
    "Change \n",
    "```yml\n",
    "eligibility-service:\n",
    "    build: ./services/dummy\n",
    "``` \n",
    "to \n",
    "\n",
    "```yml\n",
    "eligibility-service:\n",
    "    build: ./services/eligibility\n",
    "``` \n",
    "\n",
    "Then rebuild the eligibility-serviec with docker-compose: `docker-compose down`, `docker-compose build eligibility-service` and `docker-compose up`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-amateur",
   "metadata": {},
   "source": [
    "## Excercise 4: Call our eligibility service\n",
    "\n",
    "Our eligibility service now exposes our model using a REST API. We can call it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "progressive-sixth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-08-09 13:45:04--  http://eligibility-service:9000/predict\n",
      "Resolving eligibility-service (eligibility-service)... 127.0.0.1, 127.0.0.1, 127.0.0.1, ...\n",
      "Connecting to eligibility-service (eligibility-service)|127.0.0.1|:9000... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 46 [application/json]\n",
      "Saving to: ‘STDOUT’\n",
      "\n",
      "\n",
      "-                     0%[                    ]       0  --.-KB/s               {\"data\":{\"names\":[],\"ndarray\":[0]},\"meta\":{}}\n",
      "\n",
      "-                   100%[===================>]      46  --.-KB/s    in 0s      \n",
      "\n",
      "2021-08-09 13:45:04 (9.27 MB/s) - written to stdout [46/46]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O- http://eligibility-service:9000/predict --post-data '{\"data\": { \"ndarray\": [[25000, 10000]]}}' --header='Content-Type:application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-adapter",
   "metadata": {},
   "source": [
    "If you receive a succssful response \"200 OK\" you can switch to our frontend and test our service like an end user: http://localhost:8000/#order"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
